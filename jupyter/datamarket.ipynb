{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import operator\n",
    "from math import sqrt\n",
    "from functools import partial\n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\"\"\"\n",
    "https://arxiv.org/pdf/1805.08125.pdf\n",
    "\n",
    "Allocation Function. AF : (Pn, bn) → Sn, Sn ⊂ [M], the allocation function, takes as input the\n",
    "price p_n and the bid from a buyer b_n, to return the features with noise added according to the bid.\n",
    "\n",
    "Revenue Function. RF : (p_n, b_n, Y_n M, G) → r_n, r_n ∈ R+, the revenue function, takes as\n",
    "input the current price p_n, the bid and the prediction task provided by the buyer (b_n and Y_n\n",
    "respectively), to decide how much revenue r_n to extract from the buyer.\n",
    "\n",
    "Payment Division Function. PD : (S_n, Y_n ;M, G) → ψ_n, ψ_n ∈ [0, 1]|S_n|\n",
    ", the payment-division function, takes as input the set of features that were allocated XSn\n",
    "along with the prediction task Y_n, to compute ψ_n, a vector denoting the marginal value \n",
    "of each allocated feature for the prediction task.\n",
    "\n",
    "Price Update Function. PF : (Pn, bn, Yn) → Pn+1, Pn+1 ∈ RM\n",
    "+ , the price-update function, takes\n",
    "as input the current price vector Pn, the bid and the prediction task provided by the buyer (bn and Yn\n",
    "respectively) to update the price vector for each of the M features.\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Property A.1: Algorithm converges to the maximum price over time\n",
    "Description of Experiment 1.1\n",
    "Take n example datasets from Scikit-Learn [(X_i), Y_i]\n",
    "[(X_1), (X_2), …, (X_n)] are features on sale\n",
    "[Y_1, Y_2, …., Y_n] are prediction tasks “for hire”\n",
    "[b_1, b_2, ….., b_n] are bids for each prediction type  \n",
    "Dynamics\n",
    "Uniformly at random select (Y_n, b_n) as stream of buyers\n",
    "Desired outcomes of experiment  \n",
    "(p_i) converge to approximately b_i \n",
    "Why? Optimal Outcome is that price of each (feature set type) converges to bid for that that prediction task type\n",
    "Regularization helps\n",
    "Why? - Theory shows that it makes the problem “convex”\n",
    "\"\"\"\n",
    "dset_names = [\n",
    " 'load_boston',\n",
    " 'load_breast_cancer',\n",
    " 'load_diabetes',\n",
    " 'load_digits',\n",
    "]\n",
    "    \n",
    "dsets = {}\n",
    "for attr in dset_names:\n",
    "    name = attr.split('load_')[1]\n",
    "    if name:\n",
    "        dsets[name] = getattr(datasets, attr)()\n",
    "Y_dict = { name: dsets[name].target for name in dsets }\n",
    "X_dict = { name: dsets[name].data for name in dsets }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('boston', (506, 13)),\n",
       " ('breast_cancer', (569, 30)),\n",
       " ('diabetes', (442, 10)),\n",
       " ('digits', (1797, 64))]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(key, x.shape) for key, x in X_dict.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('boston', (506,)),\n",
       " ('breast_cancer', (569,)),\n",
       " ('diabetes', (442,)),\n",
       " ('digits', (1797,))]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(key, y.shape) for key, y in Y_dict.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Look at first four, up to 400 time steps (IMPORTANT: ml_algorithm is trained on all features available)\"\"\"\n",
    "X_t1 = np.concatenate([x[:400] for x in X_dict.values()], axis=1)\n",
    "Y_t1 = np.stack([y[:400] for y in Y_dict.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((400, 117), (4, 400))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_t1.shape, Y_t1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(x.shape[1] for key, x in X_dict.items()) # number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_original_columns(X_n, feature_idxs):\n",
    "    indices = [idx for (idx, price) in feature_idxs]\n",
    "    return X_n[:, indices]\n",
    "\n",
    "def gain_score(y, x):\n",
    "    r2 = r2_score(y, x)\n",
    "    return r2 if r2 > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allocation and Revenue function\n",
    "# Section 4.1\n",
    "# TODO: How can we adjust sigma for the data?\n",
    "def allocation_func(p_n, b_n, X_n, mu=0, sigma=10):\n",
    "    \"\"\"\n",
    "    Allocation function for reals\n",
    "    p_n: the price vector at previous timestep (t=n)\n",
    "    b_n: the bid at previous timestep (in $ / model_score)\n",
    "    X_n: the features available\n",
    "    \"\"\"\n",
    "    return X_n + max(0, p_n - b_n) * np.random.normal(mu, sigma, X_n.shape)\n",
    "    \n",
    "# B_epsilon parameters\n",
    "B_EPS_STEP_SIZE = 1 # dollars\n",
    "B_EPS_START = 0\n",
    "B_EPS_END = 1000\n",
    "\n",
    "def _gain_func(p_n, X_n, Y_n, ml_func, random_state, bid):\n",
    "    # Use cross-validation instead of holdout? ml_func uses CV to set params\n",
    "    X_n_degraded = allocation_func(p_n, bid, X_n)\n",
    "    _train, _test, y_n_train, y_n_test = train_test_split(X_n_degraded, Y_n, test_size=0.1, random_state=random_state)\n",
    "    ml_func.fit(_train, y_n_train)\n",
    "    return gain_score(y_n_test, ml_func.predict(_test))\n",
    "    \n",
    "def revenue_func(p_n, b_n, Y_n, context, random_state):\n",
    "    \"\"\"\n",
    "    p_n: the price at the previous timestep (t=n)\n",
    "    b_n: the bid at previous timestep (in $ / model_score)\n",
    "    Y_n: the test Y data set\n",
    "    \"\"\"\n",
    "    X_n = context.get('X_n')\n",
    "    ml_func = context.get('ml_func')\n",
    "    if X_n is None or ml_func is None:\n",
    "        return None, None\n",
    "\n",
    "    print('X_n shape: {}'.format(X_n.shape))\n",
    "    print('Y_n shape: {}'.format(Y_n.shape))\n",
    "    \n",
    "    _gain = partial(_gain_func, p_n, X_n, Y_n, ml_func, random_state)\n",
    "    \n",
    "    stopping_point = min(p_n, b_n)\n",
    "    b_n_gain = _gain(stopping_point)\n",
    "    print('b_n_gain: {}'.format(b_n_gain))\n",
    "#     if b_n_gain == 0:\n",
    "#         import pdb; pdb.set_trace()\n",
    "\n",
    "    delta_revenue_list = []\n",
    "    prev_bid = 0\n",
    "    for bid in range(0, stopping_point, B_EPS_STEP_SIZE):\n",
    "        other_gain = _gain(bid)\n",
    "        revenue = (bid - prev_bid) * (b_n_gain - other_gain)\n",
    "        prev_bid = bid\n",
    "        # If revenue would be lower with a higher bid, return previous revenue?\n",
    "        if (revenue < 0):\n",
    "            import pdb; pdb.set_trace()\n",
    "        delta_revenue_list.append(revenue)\n",
    "    return sum(delta_revenue_list), np.cumsum(delta_revenue_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 117)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_n = X_t1\n",
    "X_n.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_n shape: (400, 117)\n",
      "Y_n shape: (400,)\n",
      "b_n_gain: 0.6578052695029548\n",
      "2.63122107801 [ 0.          0.65780527  1.31561054  1.97341581  2.63122108]\n",
      "X_n shape: (400, 117)\n",
      "Y_n shape: (400,)\n",
      "b_n_gain: 0.7386892199745951\n",
      "0.529705555378 [ 0.          0.12839172  0.26309894  0.39399163  0.52970556]\n",
      "X_n shape: (400, 117)\n",
      "Y_n shape: (400,)\n",
      "b_n_gain: 0\n",
      "0 [0 0 0 0 0]\n",
      "X_n shape: (400, 117)\n",
      "Y_n shape: (400,)\n",
      "b_n_gain: 0.5420453689527003\n",
      "2.16818147581 [ 0.          0.54204537  1.08409074  1.62613611  2.16818148]\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "def test1(random_state=100):\n",
    "    clf = linear_model.LassoCV(cv=5, random_state=random_state)\n",
    "    context = {\n",
    "        'ml_func': clf,\n",
    "        'X_n': X_n,\n",
    "    }\n",
    "    b_n = 5\n",
    "    p_n = b_n\n",
    "    \n",
    "    X_n_degraded = allocation_func(p_n, b_n, X_n)\n",
    "    # assert X_n_degraded == X_n\n",
    "    assert not np.any(X_n_degraded - X_n)\n",
    "    \n",
    "    for y_choice_idx in range(Y_t1.shape[0]):\n",
    "        Y_n = Y_t1[y_choice_idx]\n",
    "        revenue, cumulative_r = revenue_func(p_n, b_n, Y_n, context, random_state)\n",
    "        print(revenue, cumulative_r)\n",
    "\n",
    "    # Cannot expect revenue to be price * gain, why did I expect this before?\n",
    "#     X_n_train, X_n_test, y_n_train, y_n_test = train_test_split(X_n, Y_n, test_size=0.1, random_state=random_state)\n",
    "#     clf.fit(X_n_train, y_n_train)\n",
    "#     expected_revenue = gain_score(y_n_test, clf.predict(X_n_test)) * b_n\n",
    "#     assert np.isclose(revenue, expected_revenue), \"{} != {}\".format(revenue, expected_revenue)\n",
    "\n",
    "test1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  6.32000000e-03   1.80000000e+01   2.31000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  2.73100000e-02   0.00000000e+00   7.07000000e+00 ...,   1.00000000e+01\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  2.72900000e-02   0.00000000e+00   7.07000000e+00 ...,   1.60000000e+01\n",
      "    9.00000000e+00   0.00000000e+00]\n",
      " ..., \n",
      " [  7.67202000e+00   0.00000000e+00   1.81000000e+01 ...,   7.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  3.83518000e+01   0.00000000e+00   1.81000000e+01 ...,   9.00000000e+00\n",
      "    9.00000000e+00   1.00000000e+00]\n",
      " [  9.91655000e+00   0.00000000e+00   1.81000000e+01 ...,   1.00000000e+01\n",
      "    1.00000000e+00   0.00000000e+00]]\n",
      "X_n shape: (400, 117)\n",
      "Y_n shape: (400,)\n",
      "b_n_gain: 0\n",
      "0 [0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "def test2(random_state=100):\n",
    "    # Why does LassoCV not work with extra features for Diabetes dataset?\n",
    "    clf = linear_model.LassoCV(cv=5, random_state=random_state)\n",
    "    context = {\n",
    "        'ml_func': clf,\n",
    "        'X_n': X_n,\n",
    "    }\n",
    "    feature_count = X_n.shape[1]\n",
    "    b_n = 10\n",
    "    p_n = 10\n",
    "    \n",
    "    X_n_degraded = allocation_func(p_n, b_n, X_n)\n",
    "    print(X_n_degraded)\n",
    "    \n",
    "    y_choice_idx = 2\n",
    "    Y_n = Y_t1[y_choice_idx]\n",
    "    warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "    revenue, cumulative_revenue_list = revenue_func(p_n, b_n, Y_n, context, random_state)\n",
    "    print(revenue, cumulative_revenue_list)\n",
    "test2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_n shape: (400, 3)\n",
      "Y_n shape: (400,)\n",
      "b_n_gain: 0\n",
      "0 [0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "def test3(feature_count=3, random_state=100):\n",
    "    clf = linear_model.LassoCV(cv=5, random_state=random_state)\n",
    "    context = {\n",
    "        'ml_func': clf,\n",
    "        'X_n': X_n[:, :feature_count],\n",
    "    }\n",
    "    b_n = 5\n",
    "    p_n = 6\n",
    "    Y_n = Y_t1[3]\n",
    "    warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "    revenue, cumulative = revenue_func(p_n, b_n, Y_n, context, random_state)\n",
    "    print(revenue, cumulative)\n",
    "test3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Payment Division Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def payment_division_func(feature_indices, Y_n, M, ml_func, K):\n",
    "    \"\"\"\n",
    "    S_n: the features allocated to buyer n\n",
    "    Y_n: the test Y data set\n",
    "    M: the number of sellers\n",
    "    gain_func: the gain function\n",
    "    K: the number of times to sample uniformly from S_n\n",
    "    \"\"\"\n",
    "    for m in feature_indicesn:\n",
    "        for k in range(K):\n",
    "            sigma_k = np.random.permutation(feature_indices)\n",
    "            #TODO: continue from line 4 of Algorithm 2\n",
    "#             _train = get_original_columns(X_n_train, feature_idxs=feature_options[:idx+1])\n",
    "#             _test = get_original_columns(X_n_test, feature_idxs=feature_options[:idx+1])\n",
    "#             gain_func.fit(_train, y_n_train)\n",
    "#             result = gain_score(y_n_test, gain_func.predict(_test))\n",
    "#             gain = gain_func(Y_n, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price Update Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_n shape: (400, 117)\n",
      "Y_n shape: (400,)\n",
      "b_n_gain: 0.5951846598328262\n",
      "X_n shape: (400, 117)\n",
      "Y_n shape: (400,)\n",
      "b_n_gain: 0.5951846598328262\n",
      "X_n shape: (400, 117)\n",
      "Y_n shape: (400,)\n",
      "b_n_gain: 0.5951846598328262\n",
      "X_n shape: (400, 117)\n",
      "Y_n shape: (400,)\n",
      "b_n_gain: 0.5951846598328262\n",
      "X_n shape: (400, 117)\n",
      "Y_n shape: (400,)\n",
      "b_n_gain: 0.5951846598328262\n",
      "X_n shape: (400, 117)\n",
      "Y_n shape: (400,)\n",
      "b_n_gain: 0.5951846598328262\n",
      "X_n shape: (400, 117)\n",
      "Y_n shape: (400,)\n",
      "b_n_gain: 0.5951846598328262\n",
      "X_n shape: (400, 117)\n",
      "Y_n shape: (400,)\n",
      "b_n_gain: 0.5951846598328262\n",
      "X_n shape: (400, 117)\n",
      "Y_n shape: (400,)\n",
      "b_n_gain: 0.5951846598328262\n",
      "X_n shape: (400, 117)\n",
      "Y_n shape: (400,)\n",
      "b_n_gain: 0.5951846598328262\n",
      "X_n shape: (400, 117)\n",
      "Y_n shape: (400,)\n",
      "b_n_gain: 0.5951846598328262\n",
      "X_n shape: (400, 117)\n",
      "Y_n shape: (400,)\n",
      "b_n_gain: 0.5951846598328262\n",
      "X_n shape: (400, 117)\n",
      "Y_n shape: (400,)\n",
      "b_n_gain: 0.5951846598328262\n",
      "X_n shape: (400, 117)\n",
      "Y_n shape: (400,)\n",
      "b_n_gain: 0.5951846598328262\n",
      "X_n shape: (400, 117)\n",
      "Y_n shape: (400,)\n",
      "b_n_gain: 0.5951846598328262\n",
      "X_n shape: (400, 117)\n",
      "Y_n shape: (400,)\n",
      "b_n_gain: 0.5951846598328262\n",
      "X_n shape: (400, 117)\n",
      "Y_n shape: (400,)\n",
      "b_n_gain: 0.5951846598328262\n",
      "X_n shape: (400, 117)\n",
      "Y_n shape: (400,)\n",
      "b_n_gain: 0.5951846598328262\n",
      "X_n shape: (400, 117)\n",
      "Y_n shape: (400,)\n",
      "b_n_gain: 0.5951846598328262\n",
      "X_n shape: (400, 117)\n",
      "Y_n shape: (400,)\n",
      "b_n_gain: 0.5951846598328262\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-e3dfe44f26ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmulti_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB_eps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mprice_update_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_t1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-e3dfe44f26ce>\u001b[0m in \u001b[0;36mprice_update_func\u001b[0;34m(b_n, Y_n, delta, random_state)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mrevenue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcumulative_r\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrevenue_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mrevenue\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mB_EPS_END\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmulti_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB_eps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mprice_update_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_t1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-e3dfe44f26ce>\u001b[0m in \u001b[0;36mmulti_weights\u001b[0;34m(B_eps, reward, learningRate, numRounds)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m# TODO: should chosenPrice affect weight update?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlearningRate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB_eps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mchosenPrice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-e3dfe44f26ce>\u001b[0m in \u001b[0;36mreward\u001b[0;34m(price)\u001b[0m\n\u001b[1;32m     27\u001b[0m     }\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mrevenue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcumulative_r\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrevenue_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mrevenue\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mB_EPS_END\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmulti_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB_eps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-6fd948851046>\u001b[0m in \u001b[0;36mrevenue_func\u001b[0;34m(p_n, b_n, Y_n, context, random_state)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mprev_bid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstopping_point\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB_EPS_STEP_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mother_gain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_gain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0mrevenue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbid\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mprev_bid\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mb_n_gain\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mother_gain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mprev_bid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-6fd948851046>\u001b[0m in \u001b[0;36m_gain_func\u001b[0;34m(p_n, X_n, Y_n, ml_func, random_state, bid)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mX_n_degraded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mallocation_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0m_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_n_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_n_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_n_degraded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mml_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_n_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgain_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_n_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mml_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1236\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy_X\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecompute\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1238\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1239\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'l1_ratio'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1240\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml1_ratio_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, check_input)\u001b[0m\n\u001b[1;32m    710\u001b[0m             X, y = check_X_y(X, y, accept_sparse='csc',\n\u001b[1;32m    711\u001b[0m                              \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'F'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 712\u001b[0;31m                              copy=X_copied, multi_output=True, y_numeric=True)\n\u001b[0m\u001b[1;32m    713\u001b[0m             y = check_array(y, order='F', copy=False, dtype=X.dtype.type,\n\u001b[1;32m    714\u001b[0m                             ensure_2d=False)\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    745\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m                     estimator=estimator)\n\u001b[0m\u001b[1;32m    748\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    520\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 522\u001b[0;31m                 \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    523\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \"\"\"\n\u001b[0;32m--> 531\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def draw(weights):\n",
    "    \"\"\"pick the index of a weight by normalizing to a probability distribution and drawing according to that distribution\"\"\"\n",
    "    return np.random.choice(range(len(weights)), p = preprocessing.normalize(weights.reshape(1, -1), norm='l1').ravel())\n",
    "\n",
    "# similar to https://github.com/j2kun/mwua/blob/master/mwua.py\n",
    "def multi_weights(B_eps, reward, learningRate = 0.1, numRounds=15):\n",
    "    weights = np.ones(len(B_eps))\n",
    "    cumulativeReward = 0\n",
    "    for t in range(numRounds):\n",
    "        chosenPrice = B_eps[draw(weights)]\n",
    "        # TODO: should chosenPrice affect weight update?\n",
    "        for i in range(len(weights)):\n",
    "            weights[i] *= (1 + learningRate * reward(B_eps[i]))\n",
    "    return chosenPrice\n",
    "\n",
    "def price_update_func(b_n, Y_n, delta=0.1, random_state=42):\n",
    "    \"\"\"\n",
    "    b_n: the current bid\n",
    "    Y_n: the test Y data set\n",
    "    delta: the learning rate for the multiplicative weights algorithm\n",
    "    \"\"\"\n",
    "    B_eps = np.arange(B_EPS_START, B_EPS_END, B_EPS_STEP_SIZE)\n",
    "    clf = linear_model.LassoCV(cv=5, random_state=100)\n",
    "    context = {\n",
    "        'ml_func': clf,\n",
    "        'X_n': X_n,\n",
    "    }\n",
    "    def reward(price):\n",
    "        revenue, cumulative_r = revenue_func(price, b_n, Y_n, context, random_state)\n",
    "        return revenue / B_EPS_END\n",
    "    return multi_weights(B_eps, reward, delta)\n",
    "\n",
    "price_update_func(20, Y_t1[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
