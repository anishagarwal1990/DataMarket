{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import operator\n",
    "from math import sqrt\n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\"\"\"\n",
    "https://arxiv.org/pdf/1805.08125.pdf\n",
    "\n",
    "Allocation Function. AF : (Pn, bn) → Sn, Sn ⊂ [M], the allocation function, takes as input the\n",
    "price vector Pn and the bid from a buyer bn, to decide which features the buyer gets allocated.\n",
    "\n",
    "Revenue Function. RF : (Pn, bn, Yn ;M, G) → rn, rn ∈ R+, the revenue function, takes as\n",
    "input the current price vector Pn, the bid and the prediction task provided by the buyer (bn and Yn\n",
    "respectively), to decide how much revenue rn to extract from the buyer.\n",
    "\n",
    "Payment Division Function. PD : (Sn, Yn ;M, G) → ψn, ψn ∈ [0, 1]|Sn|\n",
    ", the payment-division function, takes as input the set of features that were allocated XSn\n",
    "along with the prediction task Yn,\n",
    "to compute ψn, a vector denoting the marginal value of each allocated feature for the prediction task.\n",
    "\n",
    "Price Update Function. PF : (Pn, bn, Yn) → Pn+1, Pn+1 ∈ RM\n",
    "+ , the price-update function, takes\n",
    "as input the current price vector Pn, the bid and the prediction task provided by the buyer (bn and Yn\n",
    "respectively) to update the price vector for each of the M features.\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Property A.1: Algorithm converges to the maximum price vector over time\n",
    "Description of Experiment 1.1\n",
    "Take n example datasets from Scikit-Learn [(X_i), Y_i]\n",
    "[(X_1), (X_2), …, (X_n)] are features on sale\n",
    "[Y_1, Y_2, …., Y_n] are prediction tasks “for hire”\n",
    "[b_1, b_2, ….., b_n] are bids for each prediction type  \n",
    "Dynamics\n",
    "Uniformly at random select (Y_n, b_n) as stream of buyers\n",
    "Desired outcomes of experiment  \n",
    "(P_i) converge to approximately b_i \n",
    "Why? Optimal Outcome is that price of each (feature set type) converges to bid for that that prediction task type\n",
    "Regularization helps\n",
    "Why? - Theory shows that it makes the problem “convex”\n",
    "\"\"\"\n",
    "dset_names = [\n",
    " 'load_boston',\n",
    " 'load_breast_cancer',\n",
    " 'load_diabetes',\n",
    " 'load_digits',\n",
    "]\n",
    "    \n",
    "dsets = {}\n",
    "for attr in dset_names:\n",
    "    name = attr.split('load_')[1]\n",
    "    if name:\n",
    "        dsets[name] = getattr(datasets, attr)()\n",
    "Y_dict = { name: dsets[name]['target'] for name in dsets }\n",
    "X_dict = { name: dsets[name]['data'] for name in dsets }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(key, x.shape) for key, x in X_dict.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(key, y.shape) for key, y in Y_dict.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Look at first four, up to 400 time steps\"\"\"\n",
    "X_t1 = np.concatenate([x[:400] for x in X_dict.values()], axis=1)\n",
    "Y_t1 = np.stack([y[:400] for y in Y_dict.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t1.shape, Y_t1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_original_columns(X_n, feature_idxs):\n",
    "    indices = [idx for (idx, price) in feature_idxs]\n",
    "    return X_n[:, indices]\n",
    "\n",
    "def gain_score(y, x):\n",
    "    r2 = r2_score(y, x)\n",
    "    return r2 if r2 > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allocation and Revenue function\n",
    "# Section 4.1\n",
    "def revenue_func(P_n, b_n, Y_n, context, random_state):\n",
    "    \"\"\"\n",
    "    P_n: the price vector at previous timestep (t=n)\n",
    "    b_n: the bid at previous timestep (in $ / model_score)\n",
    "    Y_n: the test Y data set\n",
    "    \"\"\"\n",
    "    X_n = context.get('X_n')\n",
    "    gain_func = context.get('gain_func')\n",
    "    if X_n is None or gain_func is None:\n",
    "        return None, None\n",
    "    \n",
    "    feature_count = len(P_n)\n",
    "    feature_options = sorted(list((idx, p) for (idx, p) in enumerate(P_n) if p <= b_n), key=operator.itemgetter(1))\n",
    "    print('feature_options: {}'.format(feature_options))\n",
    "    if not feature_options:\n",
    "        return 0, None\n",
    "    \n",
    "    assert feature_count == X_n.shape[1], 'feature_count: {}, X_n.shape[1]: {}'.format(feature_count, X_n.shape[1])\n",
    "\n",
    "    # 90% train and cross-validate, 10% test\n",
    "    print('X_n shape: {}'.format(X_n.shape))\n",
    "    print('Y_n shape: {}'.format(Y_n.shape))\n",
    "    X_n_train, X_n_test, y_n_train, y_n_test = train_test_split(X_n, Y_n, test_size=0.1, random_state=random_state)\n",
    "\n",
    "    # Gain results by slice index\n",
    "    feature_indices = []\n",
    "    gain_results = []\n",
    "    for (idx, (feature_idx, feature_price)) in enumerate(feature_options):\n",
    "        _train = get_original_columns(X_n_train, feature_idxs=feature_options[:idx+1])\n",
    "        _test = get_original_columns(X_n_test, feature_idxs=feature_options[:idx+1])\n",
    "        gain_func.fit(_train, y_n_train)\n",
    "        result = gain_score(y_n_test, gain_func.predict(_test))\n",
    "        previous_result = gain_results[-1] if gain_results else 0\n",
    "        feature_indices.append(feature_idx)\n",
    "        # Only add a feature if it improves predictive gain\n",
    "        # This enforces the necessary property of the gain function\n",
    "        # always being monotonic in the features\n",
    "        if (result > previous_result):\n",
    "            gain_results.append(result)\n",
    "        else:\n",
    "            gain_results.append(previous_result)\n",
    "\n",
    "    if not gain_results:\n",
    "        raise Exception(\"gain_results empty\")\n",
    "\n",
    "    # Add the bid as the rightmost price\n",
    "    feature_indices += [-1]\n",
    "    P_n += [b_n]\n",
    "    revenue_list = []\n",
    "    prev_gain = 0\n",
    "    for idx, gain in enumerate(gain_results):\n",
    "        price_idx = feature_indices[idx]\n",
    "        price = P_n[price_idx]\n",
    "        gain = gain_results[idx]\n",
    "        gain_difference = gain - prev_gain\n",
    "        assert gain_difference >= 0, 'gain {}, prev_gain {}'.format(gain, prev_gain)\n",
    "        prev_gain = gain\n",
    "        revenue = gain_difference * price\n",
    "        revenue_list.append(revenue)\n",
    "    return sum(revenue_list), {\n",
    "        'revenue_list': revenue_list, \n",
    "        'gain_results': gain_results, \n",
    "        'feature_indices': feature_indices\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_n = X_t1\n",
    "X_n.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 1: price of all features equal to bid (all allocated, revenue = best gain * bid)\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "def test1(random_state=100):\n",
    "    clf = linear_model.LassoCV(cv=5, random_state=random_state)\n",
    "    context = {\n",
    "        'gain_func': clf,\n",
    "        'X_n': X_n,\n",
    "    }\n",
    "    feature_count = X_n.shape[1]\n",
    "    b_n = 5\n",
    "    P_n = [b_n] * feature_count\n",
    "    \n",
    "    # TODO: test each instead of randomly\n",
    "    y_choice_idx = np.random.choice(Y_t1.shape[0])\n",
    "    Y_n = Y_t1[y_choice_idx]\n",
    "\n",
    "    revenue, _ = revenue_func(P_n, b_n, Y_n, context, random_state)\n",
    "\n",
    "    X_n_train, X_n_test, y_n_train, y_n_test = train_test_split(X_n, Y_n, test_size=0.1, random_state=random_state)\n",
    "    clf.fit(X_n_train, y_n_train)\n",
    "    expected_revenue = gain_score(y_n_test, clf.predict(X_n_test)) * b_n\n",
    "    print(expected_revenue)\n",
    "#     assert np.isclose(revenue, expected_revenue), \"{} != {}\".format(revenue, expected_revenue)\n",
    "    assert revenue >= expected_revenue, \"{} != {}\".format(revenue, expected_revenue)\n",
    "test1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test2(random_state=100):\n",
    "    # Test that no features are allocated (revenue zero) when all price are greater than the bid\n",
    "    clf = linear_model.LassoCV(cv=5, random_state=random_state)\n",
    "    context = {\n",
    "        'gain_func': clf,\n",
    "        'X_n': X_n,\n",
    "    }\n",
    "    feature_count = X_n.shape[1]\n",
    "    b_n = 0.05\n",
    "    P_n = [0.1] * feature_count\n",
    "    y_choice_idx = np.random.choice(Y_t1.shape[0])\n",
    "    Y_n = Y_t1[y_choice_idx]\n",
    "    warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "    revenue, _ = revenue_func(P_n, b_n, Y_n, context, random_state)\n",
    "    assert revenue == 0\n",
    "test2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test3(feature_count=3, random_state=100):\n",
    "    clf = linear_model.LassoCV(cv=5, random_state=random_state)\n",
    "    context = {\n",
    "        'gain_func': clf,\n",
    "        'X_n': X_n[:, :feature_count],\n",
    "    }\n",
    "    b_n = 5\n",
    "    P_n = [6, 3, 2]\n",
    "    Y_n = Y_t1[3]\n",
    "    warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "    revenue, _ = revenue_func(P_n, b_n, Y_n, context, random_state)\n",
    "    print(revenue)\n",
    "    print(_)\n",
    "    P_n = [1, 1, 6]\n",
    "    revenue, _ = revenue_func(P_n, b_n, Y_n, context, random_state)\n",
    "    print(revenue)\n",
    "test3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Payment Division Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def payment_division_func(feature_indices, Y_n, M, gain_func, K):\n",
    "    \"\"\"\n",
    "    S_n: the features allocated to buyer n\n",
    "    Y_n: the test Y data set\n",
    "    M: the number of sellers\n",
    "    gain_func: the gain function\n",
    "    K: the number of times to sample uniformly from S_n\n",
    "    \"\"\"\n",
    "    for m in feature_indicesn:\n",
    "        for k in range(K):\n",
    "            sigma_k = np.random.permutation(feature_indices)\n",
    "            #TODO: continue from line 4 of Algorithm 2\n",
    "#             _train = get_original_columns(X_n_train, feature_idxs=feature_options[:idx+1])\n",
    "#             _test = get_original_columns(X_n_test, feature_idxs=feature_options[:idx+1])\n",
    "#             gain_func.fit(_train, y_n_train)\n",
    "#             result = gain_score(y_n_test, gain_func.predict(_test))\n",
    "#             gain = gain_func(Y_n, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price Update Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @Anish - look into whether this is useful, for now, leave it out\n",
    "# def smooth_kink(price_vec, bid, c):\n",
    "#     capped_price = bid + 1 / (2 * c)\n",
    "#     def _smooth(price):\n",
    "#         return price - (c * (price - bid) ** 2) / 2\n",
    "#     return [\n",
    "#         p if p <= bid else\n",
    "#         _smooth(p) if p <= bid + 1 / c else \n",
    "#         capped_price \n",
    "#         for p in price_vec\n",
    "#     ]\n",
    "\n",
    "\n",
    "def price_update_func(price_vec, bid, Y, c):\n",
    "#     smooth_prices = smooth_kink(price_vec, bid, c)\n",
    "    \n",
    "    clf = linear_model.LassoCV(cv=5, random_state=100)\n",
    "    context = {\n",
    "        'gain_func': clf,\n",
    "        'X_n': X_n[:, :3],\n",
    "    }\n",
    "    revenue, output = revenue_func(price_vec, bid, Y, context, random_state=100)\n",
    "    revenue_list = output['revenue_list']\n",
    "    revenue_list_gradient = [\n",
    "        r - revenue_list[idx - 1]\n",
    "        if idx > 0 else r\n",
    "        for idx, r, in enumerate(revenue_list)\n",
    "    ]\n",
    "    print(revenue_list_gradient)\n",
    "\n",
    "price_update_func([2, 3, 4], 3, Y_t1[3], c=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
