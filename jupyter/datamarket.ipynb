{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import operator\n",
    "from math import sqrt\n",
    "from functools import partial\n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\"\"\"\n",
    "https://arxiv.org/pdf/1805.08125.pdf\n",
    "\n",
    "Allocation Function. AF : (Pn, bn) → Sn, Sn ⊂ [M], the allocation function, takes as input the\n",
    "price p_n and the bid from a buyer b_n, to return the features with noise added according to the bid.\n",
    "\n",
    "Revenue Function. RF : (p_n, b_n, Y_n M, G) → r_n, r_n ∈ R+, the revenue function, takes as\n",
    "input the current price p_n, the bid and the prediction task provided by the buyer (b_n and Y_n\n",
    "respectively), to decide how much revenue r_n to extract from the buyer.\n",
    "\n",
    "Payment Division Function. PD : (S_n, Y_n ;M, G) → ψ_n, ψ_n ∈ [0, 1]|S_n|\n",
    ", the payment-division function, takes as input the set of features that were allocated XSn\n",
    "along with the prediction task Y_n, to compute ψ_n, a vector denoting the marginal value \n",
    "of each allocated feature for the prediction task.\n",
    "\n",
    "Price Update Function. PF : (Pn, bn, Yn) → Pn+1, Pn+1 ∈ RM\n",
    "+ , the price-update function, takes\n",
    "as input the current price vector Pn, the bid and the prediction task provided by the buyer (bn and Yn\n",
    "respectively) to update the price vector for each of the M features.\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Property A.1: Algorithm converges to the maximum price over time\n",
    "Description of Experiment 1.1\n",
    "Take n example datasets from Scikit-Learn [(X_i), Y_i]\n",
    "[(X_1), (X_2), …, (X_n)] are features on sale\n",
    "[Y_1, Y_2, …., Y_n] are prediction tasks “for hire”\n",
    "[b_1, b_2, ….., b_n] are bids for each prediction type  \n",
    "Dynamics\n",
    "Uniformly at random select (Y_n, b_n) as stream of buyers\n",
    "Desired outcomes of experiment  \n",
    "(p_i) converge to approximately b_i \n",
    "Why? Optimal Outcome is that price of each (feature set type) converges to bid for that that prediction task type\n",
    "Regularization helps\n",
    "Why? - Theory shows that it makes the problem “convex”\n",
    "\"\"\"\n",
    "dset_names = [\n",
    " 'load_boston',\n",
    " 'load_breast_cancer',\n",
    " 'load_diabetes',\n",
    " 'load_digits',\n",
    "]\n",
    "    \n",
    "dsets = {}\n",
    "for attr in dset_names:\n",
    "    name = attr.split('load_')[1]\n",
    "    if name:\n",
    "        dsets[name] = getattr(datasets, attr)()\n",
    "Y_dict = { name: dsets[name].target for name in dsets }\n",
    "X_dict = { name: dsets[name].data for name in dsets }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('boston', (506, 13)),\n",
       " ('breast_cancer', (569, 30)),\n",
       " ('diabetes', (442, 10)),\n",
       " ('digits', (1797, 64))]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(key, x.shape) for key, x in X_dict.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('boston', (506,)),\n",
       " ('breast_cancer', (569,)),\n",
       " ('diabetes', (442,)),\n",
       " ('digits', (1797,))]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(key, y.shape) for key, y in Y_dict.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Look at first four, up to 400 time steps (IMPORTANT: ml_algorithm is trained on all features available)\"\"\"\n",
    "X_t1 = np.concatenate([x[:400] for x in X_dict.values()], axis=1)\n",
    "Y_t1 = np.stack([y[:400] for y in Y_dict.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((400, 117), (4, 400))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_t1.shape, Y_t1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(x.shape[1] for key, x in X_dict.items()) # number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_original_columns(X_n, feature_idxs):\n",
    "    indices = [idx for (idx, price) in feature_idxs]\n",
    "    return X_n[:, indices]\n",
    "\n",
    "def gain_score(y, x):\n",
    "    r2 = r2_score(y, x)\n",
    "    return r2 if r2 > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allocation and Revenue function\n",
    "# Section 4.1\n",
    "# TODO: How can we adjust sigma for the data?\n",
    "def allocation_func(p_n, b_n, X_n, mu=0, sigma=10):\n",
    "    \"\"\"\n",
    "    Allocation function for reals\n",
    "    p_n: the price vector at previous timestep (t=n)\n",
    "    b_n: the bid at previous timestep (in $ / model_score)\n",
    "    X_n: the features available\n",
    "    \"\"\"\n",
    "    return X_n + max(0, p_n - b_n) * np.random.normal(mu, sigma, X_n.shape)\n",
    "    \n",
    "# B_epsilon parameters\n",
    "B_EPS_STEP_SIZE = 1 # dollars\n",
    "B_EPS_START = 0\n",
    "B_EPS_END = 1000\n",
    "\n",
    "def _gain_func(p_n, X_n, Y_n, ml_func, random_state, bid):\n",
    "    # Use cross-validation instead of holdout? ml_func uses CV to set params\n",
    "    X_n_degraded = allocation_func(p_n, bid, X_n)\n",
    "    _train, _test, y_n_train, y_n_test = train_test_split(X_n_degraded, Y_n, test_size=0.1, random_state=random_state)\n",
    "    ml_func.fit(_train, y_n_train)\n",
    "    return gain_score(y_n_test, ml_func.predict(_test))\n",
    "    \n",
    "def revenue_func(p_n, b_n, Y_n, context, random_state):\n",
    "    \"\"\"\n",
    "    p_n: the price at the previous timestep (t=n)\n",
    "    b_n: the bid at previous timestep (in $ / model_score)\n",
    "    Y_n: the test Y data set\n",
    "    \"\"\"\n",
    "    X_n = context.get('X_n')\n",
    "    ml_func = context.get('ml_func')\n",
    "    if X_n is None or ml_func is None:\n",
    "        return None, None\n",
    "\n",
    "    print('X_n shape: {}'.format(X_n.shape))\n",
    "    print('Y_n shape: {}'.format(Y_n.shape))\n",
    "    \n",
    "    _gain = partial(_gain_func, p_n, X_n, Y_n, ml_func, random_state)\n",
    "    \n",
    "    stopping_point = min(p_n, b_n)\n",
    "    b_n_gain = _gain(stopping_point)\n",
    "    print('b_n_gain: {}'.format(b_n_gain))\n",
    "#     if b_n_gain == 0:\n",
    "#         import pdb; pdb.set_trace()\n",
    "\n",
    "    delta_revenue_list = []\n",
    "    prev_bid = 0\n",
    "    for bid in range(0, stopping_point, B_EPS_STEP_SIZE):\n",
    "        other_gain = _gain(bid)\n",
    "        revenue = (bid - prev_bid) * (b_n_gain - other_gain)\n",
    "        prev_bid = bid\n",
    "        # If revenue would be lower with a higher bid, return previous revenue?\n",
    "        if (revenue < 0):\n",
    "            import pdb; pdb.set_trace()\n",
    "        delta_revenue_list.append(revenue)\n",
    "    return sum(delta_revenue_list), np.cumsum(delta_revenue_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 117)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_n = X_t1\n",
    "X_n.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_n shape: (400, 117)\n",
      "Y_n shape: (400,)\n",
      "b_n_gain: 0.6578052695029548\n",
      "2.3934599306 [ 0.          0.65780527  1.31561054  1.94850759  2.39345993]\n",
      "X_n shape: (400, 117)\n",
      "Y_n shape: (400,)\n",
      "b_n_gain: 0.7386892199745951\n",
      "0.399104906004 [ 0.          0.14695417  0.26250004  0.36424204  0.39910491]\n",
      "X_n shape: (400, 117)\n",
      "Y_n shape: (400,)\n",
      "b_n_gain: 0\n",
      "0 [0 0 0 0 0]\n",
      "X_n shape: (400, 117)\n",
      "Y_n shape: (400,)\n",
      "b_n_gain: 0.5420453689527003\n",
      "2.16818147581 [ 0.          0.54204537  1.08409074  1.62613611  2.16818148]\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "def test1(random_state=100):\n",
    "    clf = linear_model.LassoCV(cv=5, random_state=random_state)\n",
    "    context = {\n",
    "        'ml_func': clf,\n",
    "        'X_n': X_n,\n",
    "    }\n",
    "    b_n = 5\n",
    "    p_n = b_n\n",
    "    \n",
    "    X_n_degraded = allocation_func(p_n, b_n, X_n)\n",
    "    # assert X_n_degraded == X_n\n",
    "    assert not np.any(X_n_degraded - X_n)\n",
    "    \n",
    "    for y_choice_idx in range(Y_t1.shape[0]):\n",
    "        Y_n = Y_t1[y_choice_idx]\n",
    "        revenue, cumulative_r = revenue_func(p_n, b_n, Y_n, context, random_state)\n",
    "        print(revenue, cumulative_r)\n",
    "\n",
    "    # Cannot expect revenue to be price * gain, why did I expect this before?\n",
    "#     X_n_train, X_n_test, y_n_train, y_n_test = train_test_split(X_n, Y_n, test_size=0.1, random_state=random_state)\n",
    "#     clf.fit(X_n_train, y_n_train)\n",
    "#     expected_revenue = gain_score(y_n_test, clf.predict(X_n_test)) * b_n\n",
    "#     assert np.isclose(revenue, expected_revenue), \"{} != {}\".format(revenue, expected_revenue)\n",
    "\n",
    "test1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  6.32000000e-03   1.80000000e+01   2.31000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  2.73100000e-02   0.00000000e+00   7.07000000e+00 ...,   1.00000000e+01\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  2.72900000e-02   0.00000000e+00   7.07000000e+00 ...,   1.60000000e+01\n",
      "    9.00000000e+00   0.00000000e+00]\n",
      " ..., \n",
      " [  7.67202000e+00   0.00000000e+00   1.81000000e+01 ...,   7.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  3.83518000e+01   0.00000000e+00   1.81000000e+01 ...,   9.00000000e+00\n",
      "    9.00000000e+00   1.00000000e+00]\n",
      " [  9.91655000e+00   0.00000000e+00   1.81000000e+01 ...,   1.00000000e+01\n",
      "    1.00000000e+00   0.00000000e+00]]\n",
      "X_n shape: (400, 117)\n",
      "Y_n shape: (400,)\n",
      "b_n_gain: 0\n",
      "0 [0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "def test2(random_state=100):\n",
    "    # Why does LassoCV not work with extra features for Diabetes dataset?\n",
    "    clf = linear_model.LassoCV(cv=5, random_state=random_state)\n",
    "    context = {\n",
    "        'ml_func': clf,\n",
    "        'X_n': X_n,\n",
    "    }\n",
    "    feature_count = X_n.shape[1]\n",
    "    b_n = 10\n",
    "    p_n = 10\n",
    "    \n",
    "    X_n_degraded = allocation_func(p_n, b_n, X_n)\n",
    "    print(X_n_degraded)\n",
    "    \n",
    "    y_choice_idx = 2\n",
    "    Y_n = Y_t1[y_choice_idx]\n",
    "    warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "    revenue, cumulative_revenue_list = revenue_func(p_n, b_n, Y_n, context, random_state)\n",
    "    print(revenue, cumulative_revenue_list)\n",
    "test2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_n shape: (400, 3)\n",
      "Y_n shape: (400,)\n",
      "b_n_gain: 0\n",
      "0 [0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "def test3(feature_count=3, random_state=100):\n",
    "    clf = linear_model.LassoCV(cv=5, random_state=random_state)\n",
    "    context = {\n",
    "        'ml_func': clf,\n",
    "        'X_n': X_n[:, :feature_count],\n",
    "    }\n",
    "    b_n = 5\n",
    "    p_n = 6\n",
    "    Y_n = Y_t1[3]\n",
    "    warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "    revenue, cumulative = revenue_func(p_n, b_n, Y_n, context, random_state)\n",
    "    print(revenue, cumulative)\n",
    "test3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Payment Division Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def payment_division_func(feature_indices, Y_n, M, ml_func, K):\n",
    "    \"\"\"\n",
    "    S_n: the features allocated to buyer n\n",
    "    Y_n: the test Y data set\n",
    "    M: the number of sellers\n",
    "    gain_func: the gain function\n",
    "    K: the number of times to sample uniformly from S_n\n",
    "    \"\"\"\n",
    "    for m in feature_indicesn:\n",
    "        for k in range(K):\n",
    "            sigma_k = np.random.permutation(feature_indices)\n",
    "            #TODO: continue from line 4 of Algorithm 2\n",
    "#             _train = get_original_columns(X_n_train, feature_idxs=feature_options[:idx+1])\n",
    "#             _test = get_original_columns(X_n_test, feature_idxs=feature_options[:idx+1])\n",
    "#             gain_func.fit(_train, y_n_train)\n",
    "#             result = gain_score(y_n_test, gain_func.predict(_test))\n",
    "#             gain = gain_func(Y_n, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price Update Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "price_update_func() got an unexpected keyword argument 'c'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-9a6377440e53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mrevenue_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'revenue_list'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mprice_update_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_t1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: price_update_func() got an unexpected keyword argument 'c'"
     ]
    }
   ],
   "source": [
    "def draw(weights):\n",
    "    \"\"\"pick a weight by normalizing to a probability distribution and drawing according to that distribution\"\"\"\n",
    "    return np.random.choice(weights, p = preprocessing.normalize(weights.reshape(1, -1), norm='l1').ravel())\n",
    "\n",
    "def multiplicative_weights(B_eps, observeOutcome, reward, learningRate, numRounds):\n",
    "    weights = np.ones(len(B_eps))\n",
    "    cumulativeReward = 0\n",
    "\n",
    "    for t in range(numRounds):\n",
    "        chosenPrice = prices[draw(weights)]\n",
    "\n",
    "#         https://github.com/j2kun/mwua/blob/master/mwua.py\n",
    "#         outcome = observeOutcome(t, weights, chosenPrice)\n",
    "#         thisRoundReward = reward(chosenPrice, outcome)\n",
    "#         cumulativeReward += thisRoundReward\n",
    "\n",
    "# TODO: how can we find reward?\n",
    "\n",
    "        for i in range(len(weights)):\n",
    "            weights[i] *= (1 + learningRate * reward(objects[i], outcome))\n",
    "\n",
    "    return weights\n",
    "\n",
    "def price_update_func(bid, Y_n, delta):\n",
    "    \"\"\"\n",
    "    bid: the current bid\n",
    "    Y_n: the test Y data set\n",
    "    B: bounded set from which bids are chosen \n",
    "    delta: the learning rate for the multiplicative weights algorithm\n",
    "    \"\"\"\n",
    "    B_eps = np.arange(B_EPS_START, B_EPS_END, B_EPS_STEP_SIZE)\n",
    "    clf = linear_model.LassoCV(cv=5, random_state=100)\n",
    "    context = {\n",
    "        'gain_func': clf,\n",
    "        'X_n': X_n[:, :3],\n",
    "    }\n",
    "    revenue, output = revenue_func(price_vec, bid, Y_n, context, random_state=100)\n",
    "    revenue_list = output['revenue_list']\n",
    "\n",
    "price_update_func([2, 3, 4], 3, Y_t1[3], c=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
