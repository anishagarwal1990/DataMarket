{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import operator\n",
    "from math import sqrt\n",
    "from functools import partial\n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\"\"\"\n",
    "https://arxiv.org/pdf/1805.08125.pdf\n",
    "\n",
    "Allocation Function. AF : (Pn, bn) → Sn, Sn ⊂ [M], the allocation function, takes as input the\n",
    "price p_n and the bid from a buyer b_n, to return the features with noise added according to the bid.\n",
    "\n",
    "Revenue Function. RF : (p_n, b_n, Y_n M, G) → r_n, r_n ∈ R+, the revenue function, takes as\n",
    "input the current price p_n, the bid and the prediction task provided by the buyer (b_n and Y_n\n",
    "respectively), to decide how much revenue r_n to extract from the buyer.\n",
    "\n",
    "Payment Division Function. PD : (S_n, Y_n ;M, G) → ψ_n, ψ_n ∈ [0, 1]|S_n|\n",
    ", the payment-division function, takes as input the set of features that were allocated XSn\n",
    "along with the prediction task Y_n, to compute ψ_n, a vector denoting the marginal value \n",
    "of each allocated feature for the prediction task.\n",
    "\n",
    "Price Update Function. PF : (Pn, bn, Yn) → Pn+1, Pn+1 ∈ RM\n",
    "+ , the price-update function, takes\n",
    "as input the current price vector Pn, the bid and the prediction task provided by the buyer (bn and Yn\n",
    "respectively) to update the price vector for each of the M features.\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Property A.1: Algorithm converges to the maximum price over time\n",
    "Description of Experiment 1.1\n",
    "Take n example datasets from Scikit-Learn [(X_i), Y_i]\n",
    "[(X_1), (X_2), …, (X_n)] are features on sale\n",
    "[Y_1, Y_2, …., Y_n] are prediction tasks “for hire”\n",
    "[b_1, b_2, ….., b_n] are bids for each prediction type  \n",
    "Dynamics\n",
    "Uniformly at random select (Y_n, b_n) as stream of buyers\n",
    "Desired outcomes of experiment  \n",
    "(p_i) converge to approximately b_i \n",
    "Why? Optimal Outcome is that price of each (feature set type) converges to bid for that that prediction task type\n",
    "Regularization helps\n",
    "Why? - Theory shows that it makes the problem “convex”\n",
    "\"\"\"\n",
    "dset_names = [\n",
    " 'load_boston',\n",
    " 'load_breast_cancer',\n",
    " 'load_diabetes',\n",
    " 'load_digits',\n",
    "]\n",
    "    \n",
    "dsets = {}\n",
    "for attr in dset_names:\n",
    "    name = attr.split('load_')[1]\n",
    "    if name:\n",
    "        dsets[name] = getattr(datasets, attr)()\n",
    "Y_dict = { name: dsets[name].target for name in dsets }\n",
    "X_dict = { name: dsets[name].data for name in dsets }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('boston', (506, 13)),\n",
       " ('breast_cancer', (569, 30)),\n",
       " ('diabetes', (442, 10)),\n",
       " ('digits', (1797, 64))]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(key, x.shape) for key, x in X_dict.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('boston', (506,)),\n",
       " ('breast_cancer', (569,)),\n",
       " ('diabetes', (442,)),\n",
       " ('digits', (1797,))]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(key, y.shape) for key, y in Y_dict.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Look at first four, up to 400 time steps (IMPORTANT: ml_algorithm is trained on all features available)\"\"\"\n",
    "X_t1_raw = np.concatenate([x[:400] for x in X_dict.values()], axis=1)\n",
    "Y_t1 = np.stack([y[:400] for y in Y_dict.values()])\n",
    "# normalize each dataset to [0,1] in order to have added noise similarly affect each stream \n",
    "X_t1 = preprocessing.normalize(X_t1_raw, axis=0, norm='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((400, 117), (4, 400))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_t1_raw.shape, Y_t1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(x.shape[1] for key, x in X_dict.items()) # number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_original_columns(X_n, feature_idxs):\n",
    "    indices = [idx for (idx, price) in feature_idxs]\n",
    "    return X_n[:, indices]\n",
    "\n",
    "def gain_score(y, x):\n",
    "    r2 = r2_score(y, x)\n",
    "    return r2 if r2 > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allocation and Revenue function\n",
    "# Section 4.1\n",
    "# TODO: How can we adjust sigma for the data?\n",
    "noise_at_timestep = {}\n",
    "def allocation_func(p_n, b_n, X_n, timestep, mu=0, sigma=0.1):\n",
    "    \"\"\"\n",
    "    Allocation function for reals\n",
    "    p_n: the price vector at previous timestep (t=n)\n",
    "    b_n: the bid at previous timestep (in $ / model_score)\n",
    "    X_n: the features available\n",
    "    \"\"\"\n",
    "    global noise_at_timestep\n",
    "    try:\n",
    "        noise = noise_at_timestep[timestep]\n",
    "    except KeyError:\n",
    "        noise = np.random.normal(mu, sigma, X_n.shape)\n",
    "        noise_at_timestep[timestep] = noise \n",
    "    return X_n + max(0, p_n - b_n) * noise\n",
    "    \n",
    "# B_epsilon parameters\n",
    "B_EPS_STEP_SIZE = 1 # dollars\n",
    "B_EPS_START = 0\n",
    "B_EPS_END = 100\n",
    "\n",
    "def _gain_func(p_n, X_n, Y_n, ml_func, random_state, bid):\n",
    "    # Use cross-validation instead of holdout? ml_func uses CV to set params\n",
    "    X_n_degraded = allocation_func(p_n, bid, X_n, timestep=0)\n",
    "    _train, _test, y_n_train, y_n_test = train_test_split(X_n_degraded, Y_n, test_size=0.1, random_state=random_state)\n",
    "    ml_func.fit(_train, y_n_train)\n",
    "    return gain_score(y_n_test, ml_func.predict(_test))\n",
    "    \n",
    "def revenue_func(p_n, b_n, Y_n, context, random_state):\n",
    "    \"\"\"\n",
    "    p_n: the price at the previous timestep (t=n)\n",
    "    b_n: the bid at previous timestep (in $ / model_score)\n",
    "    Y_n: the test Y data set\n",
    "    \"\"\"\n",
    "    X_n = context.get('X_n')\n",
    "    ml_func = context.get('ml_func')\n",
    "    if X_n is None or ml_func is None:\n",
    "        return None, None\n",
    "\n",
    "    print('price: {}'.format(p_n))\n",
    "    print('bid: {}'.format(b_n))\n",
    "    \n",
    "    _gain = partial(_gain_func, p_n, X_n, Y_n, ml_func, random_state)\n",
    "    \n",
    "    stopping_point = min(p_n, b_n)\n",
    "    b_n_gain = _gain(stopping_point)\n",
    "    print('b_n_gain: {}'.format(b_n_gain))\n",
    "#     if b_n_gain == 0:\n",
    "#         import pdb; pdb.set_trace()\n",
    "\n",
    "    delta_revenue_list = []\n",
    "    prev_bid = 0\n",
    "    for bid in range(0, stopping_point, B_EPS_STEP_SIZE):\n",
    "        other_gain = _gain(bid)\n",
    "        revenue = (bid - prev_bid) * (b_n_gain - other_gain)\n",
    "        # If revenue would be greater with a lower bid, no new revenue\n",
    "        if (revenue < 0):\n",
    "            revenue = 0\n",
    "        prev_bid = bid\n",
    "        delta_revenue_list.append(revenue)\n",
    "    return sum(delta_revenue_list), np.cumsum(delta_revenue_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 117)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_n = X_t1\n",
    "X_n.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "price: 5\n",
      "bid: 5\n",
      "b_n_gain: 0.6828283019189709\n",
      "2.18934392682 [ 0.          0.6828283   1.34470017  1.8814094   2.18934393]\n",
      "price: 5\n",
      "bid: 5\n",
      "b_n_gain: 0.7341734278978391\n",
      "0.722768700973 [ 0.          0.35832286  0.59955626  0.70606283  0.7227687 ]\n",
      "price: 5\n",
      "bid: 5\n",
      "b_n_gain: 0.29584189517603254\n",
      "0.562519868618 [ 0.          0.21912846  0.40564661  0.51557029  0.56251987]\n",
      "price: 5\n",
      "bid: 5\n",
      "b_n_gain: 0.5702465874176466\n",
      "1.05647196553 [ 0.          0.47519148  0.84587794  1.0323062   1.05647197]\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "def test1(random_state=100):\n",
    "    clf = linear_model.LassoCV(cv=5, random_state=random_state)\n",
    "    context = {\n",
    "        'ml_func': clf,\n",
    "        'X_n': X_n,\n",
    "    }\n",
    "    b_n = 5\n",
    "    p_n = b_n\n",
    "    \n",
    "    X_n_degraded = allocation_func(p_n, b_n, X_n, timestep=0)\n",
    "    # assert X_n_degraded == X_n\n",
    "    assert not np.any(X_n_degraded - X_n)\n",
    "    \n",
    "    for y_choice_idx in range(Y_t1.shape[0]):\n",
    "        Y_n = Y_t1[y_choice_idx]\n",
    "        revenue, cumulative_r = revenue_func(p_n, b_n, Y_n, context, random_state)\n",
    "        print(revenue, cumulative_r)\n",
    "\n",
    "test1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "price: 10\n",
      "bid: 9\n",
      "b_n_gain: 0.7174675561151411\n",
      "3.42805258651 [ 0.          0.65939321  1.27268677  1.83413909  2.33755274  2.77210737\n",
      "  3.11372436  3.33825189  3.42805259]\n",
      "price: 10\n",
      "bid: 9\n",
      "b_n_gain: 0.7174675561151411\n",
      "3.42805258651 [ 0.          0.65939321  1.27268677  1.83413909  2.33755274  2.77210737\n",
      "  3.11372436  3.33825189  3.42805259]\n",
      "price: 10\n",
      "bid: 9\n",
      "b_n_gain: 0.7174675561151411\n",
      "3.42805258651 [ 0.          0.65939321  1.27268677  1.83413909  2.33755274  2.77210737\n",
      "  3.11372436  3.33825189  3.42805259]\n",
      "price: 10\n",
      "bid: 9\n",
      "b_n_gain: 0.7174675561151411\n",
      "3.42805258651 [ 0.          0.65939321  1.27268677  1.83413909  2.33755274  2.77210737\n",
      "  3.11372436  3.33825189  3.42805259]\n",
      "price: 10\n",
      "bid: 9\n",
      "b_n_gain: 0.7174675561151411\n",
      "3.42805258651 [ 0.          0.65939321  1.27268677  1.83413909  2.33755274  2.77210737\n",
      "  3.11372436  3.33825189  3.42805259]\n",
      "price: 10\n",
      "bid: 9\n",
      "b_n_gain: 0.7174675561151411\n",
      "3.42805258651 [ 0.          0.65939321  1.27268677  1.83413909  2.33755274  2.77210737\n",
      "  3.11372436  3.33825189  3.42805259]\n",
      "price: 10\n",
      "bid: 9\n",
      "b_n_gain: 0.7174675561151411\n",
      "3.42805258651 [ 0.          0.65939321  1.27268677  1.83413909  2.33755274  2.77210737\n",
      "  3.11372436  3.33825189  3.42805259]\n",
      "price: 10\n",
      "bid: 9\n",
      "b_n_gain: 0.7174675561151411\n",
      "3.42805258651 [ 0.          0.65939321  1.27268677  1.83413909  2.33755274  2.77210737\n",
      "  3.11372436  3.33825189  3.42805259]\n",
      "price: 10\n",
      "bid: 9\n",
      "b_n_gain: 0.7174675561151411\n",
      "3.42805258651 [ 0.          0.65939321  1.27268677  1.83413909  2.33755274  2.77210737\n",
      "  3.11372436  3.33825189  3.42805259]\n",
      "price: 10\n",
      "bid: 9\n",
      "b_n_gain: 0.7174675561151411\n",
      "3.42805258651 [ 0.          0.65939321  1.27268677  1.83413909  2.33755274  2.77210737\n",
      "  3.11372436  3.33825189  3.42805259]\n"
     ]
    }
   ],
   "source": [
    "def test2(random_state=100):\n",
    "    # Why does LassoCV not work with extra features for Diabetes dataset?\n",
    "    clf = linear_model.LassoCV(cv=5, random_state=random_state)\n",
    "    context = {\n",
    "        'ml_func': clf,\n",
    "        'X_n': X_n,\n",
    "    }\n",
    "    feature_count = X_n.shape[1]\n",
    "    b_n = 9\n",
    "    p_n = 10\n",
    "        \n",
    "    y_choice_idx = 1\n",
    "    Y_n = Y_t1[y_choice_idx]\n",
    "    warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "    for i in range(3):\n",
    "        revenue, cumulative_revenue_list = revenue_func(p_n, b_n, Y_n, context, random_state)\n",
    "        print(revenue, cumulative_revenue_list)\n",
    "test2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "price: 6\n",
      "bid: 5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (400,3) (400,117) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-a2d94d5ceb74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mrevenue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcumulative\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrevenue_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrevenue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcumulative\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mtest3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-a2d94d5ceb74>\u001b[0m in \u001b[0;36mtest3\u001b[0;34m(feature_count, random_state)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mY_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY_t1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilterwarnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mConvergenceWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mrevenue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcumulative\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrevenue_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrevenue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcumulative\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mtest3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-1e37241824fd>\u001b[0m in \u001b[0;36mrevenue_func\u001b[0;34m(p_n, b_n, Y_n, context, random_state)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mstopping_point\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mb_n_gain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_gain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstopping_point\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'b_n_gain: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_n_gain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;31m#     if b_n_gain == 0:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-1e37241824fd>\u001b[0m in \u001b[0;36m_gain_func\u001b[0;34m(p_n, X_n, Y_n, ml_func, random_state, bid)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_gain_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mml_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# Use cross-validation instead of holdout? ml_func uses CV to set params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mX_n_degraded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mallocation_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimestep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0m_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_n_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_n_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_n_degraded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mml_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_n_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-1e37241824fd>\u001b[0m in \u001b[0;36mallocation_func\u001b[0;34m(p_n, b_n, X_n, timestep, mu, sigma)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_n\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mnoise_at_timestep\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtimestep\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mX_n\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_n\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mb_n\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# B_epsilon parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (400,3) (400,117) "
     ]
    }
   ],
   "source": [
    "def test3(feature_count=3, random_state=100):\n",
    "    clf = linear_model.LassoCV(cv=5, random_state=random_state)\n",
    "    context = {\n",
    "        'ml_func': clf,\n",
    "        'X_n': X_n[:, :feature_count],\n",
    "    }\n",
    "    b_n = 5\n",
    "    p_n = 6\n",
    "    Y_n = Y_t1[3]\n",
    "    warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "    revenue, cumulative = revenue_func(p_n, b_n, Y_n, context, random_state)\n",
    "    print(revenue, cumulative)\n",
    "test3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Payment Division Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def payment_division_func(feature_indices, Y_n, M, ml_func, K):\n",
    "    \"\"\"\n",
    "    S_n: the features allocated to buyer n\n",
    "    Y_n: the test Y data set\n",
    "    M: the number of sellers\n",
    "    gain_func: the gain function\n",
    "    K: the number of times to sample uniformly from S_n\n",
    "    \"\"\"\n",
    "    for m in feature_indicesn:\n",
    "        for k in range(K):\n",
    "            sigma_k = np.random.permutation(feature_indices)\n",
    "            #TODO: continue from line 4 of Algorithm 2\n",
    "#             _train = get_original_columns(X_n_train, feature_idxs=feature_options[:idx+1])\n",
    "#             _test = get_original_columns(X_n_test, feature_idxs=feature_options[:idx+1])\n",
    "#             gain_func.fit(_train, y_n_train)\n",
    "#             result = gain_score(y_n_test, gain_func.predict(_test))\n",
    "#             gain = gain_func(Y_n, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price Update Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(weights):\n",
    "    \"\"\"pick the index of a weight by normalizing to a probability distribution and drawing according to that distribution\"\"\"\n",
    "    return np.random.choice(range(len(weights)), p = preprocessing.normalize(weights.reshape(1, -1), norm='l1').ravel())\n",
    "\n",
    "B_eps = np.arange(B_EPS_START, B_EPS_END, B_EPS_STEP_SIZE)\n",
    "weights = np.ones(len(B_eps))\n",
    "def multi_weights(B_eps, reward, learningRate = 0.1):\n",
    "    global weights\n",
    "    print(weights)\n",
    "    for i in range(len(weights)):\n",
    "        weights[i] *= (1 + learningRate * reward(B_eps[i]))\n",
    "    return B_eps[draw(weights)]\n",
    "\n",
    "def price_update_func(b_n, Y_n, delta=0.1, random_state=42):\n",
    "    \"\"\"\n",
    "    b_n: the current bid\n",
    "    Y_n: the test Y data set\n",
    "    delta: the learning rate for the multiplicative weights algorithm\n",
    "    \"\"\"\n",
    "    clf = linear_model.LassoCV(cv=5, random_state=100)\n",
    "    context = {\n",
    "        'ml_func': clf,\n",
    "        'X_n': X_n,\n",
    "    }\n",
    "    def reward(price):\n",
    "        revenue, cumulative_r = revenue_func(price, b_n, Y_n, context, random_state)\n",
    "        return revenue / B_EPS_END\n",
    "    return multi_weights(B_eps, reward, delta)\n",
    "\n",
    "price_update_func(5, Y_t1[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
