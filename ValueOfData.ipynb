{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import operator\n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\"\"\"\n",
    "Property A.1: Algorithm converges to the maximum price vector over time\n",
    "Description of Experiment 1.1\n",
    "Take n example datasets from Scikit-Learn [(X_i), Y_i]\n",
    "[(X_1), (X_2), …, (X_n)] are features on sale\n",
    "[Y_1, Y_2, …., Y_n] are prediction tasks “for hire”\n",
    "[b_1, b_2, ….., b_n] are bids for each prediction type  \n",
    "Dynamics\n",
    "Uniformly at random select (Y_n, b_n) as stream of buyers\n",
    "Desired outcomes of experiment  \n",
    "(P_i) converge to approximately b_i \n",
    "Why? Optimal Outcome is that price of each (feature set type) converges to bid for that that prediction task type\n",
    "Regularization helps\n",
    "Why? - Theory shows that it makes the problem “convex”\n",
    "\"\"\"\n",
    "dset_names = ['load_boston',\n",
    " 'load_breast_cancer',\n",
    " 'load_diabetes',\n",
    " 'load_digits',\n",
    " 'load_iris',\n",
    " 'load_linnerud',\n",
    " 'load_wine']\n",
    "    \n",
    "dsets = {}\n",
    "for attr in dset_names:\n",
    "    name = attr.split('load_')[1]\n",
    "    if name:\n",
    "        dsets[name] = getattr(datasets, attr)()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = [dsets[name]['target'] for name in dsets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [dsets[name]['data'] for name in dsets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(506, 0), (569, 1), (442, 2), (1797, 3), (150, 4), (60, 5), (178, 6)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(x.size, i) for i, x in enumerate(Y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Look at first four, up to 400 time steps\"\"\"\n",
    "X_t1 = [x[:400]for x in X[:4]]\n",
    "Y_t1 = [y[:400] for y in Y[:4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 101\n",
    "# 70% train, 20% validate, 10% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_t1[0], Y_t1[0], test_size=0.1, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LassoCV(alphas=None, copy_X=True, cv=5, eps=0.001, fit_intercept=True,\n",
       "    max_iter=1000, n_alphas=100, n_jobs=1, normalize=False, positive=False,\n",
       "    precompute='auto', random_state=101, selection='cyclic', tol=0.0001,\n",
       "    verbose=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = linear_model.LassoCV(cv=5, random_state=SEED)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4414395287471896"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Algorithm2) CF(bn,  Pn,  rn,  Yn,  n,  c,B,  ρn)\n",
    "#  1: fbnn(Pn)  =−PF(Pn,  bn,  Yn)\n",
    "#  2: for all i∈[M] do \n",
    "#  3:   if Pn(i)≤bn then\n",
    "#  4:     Pˆn(i) = Pˆn\n",
    "#  5:   else if bn<Pn(i)≤bn+1/c then\n",
    "#  6:     Pˆn(i)=Pn+c2(Pn−bn)2\n",
    "#  7:   else\n",
    "#  8:     Pˆn(i)=bn+12c\n",
    "#  9:   end if\n",
    "# 10: end for\n",
    "# 11: gn = ∂{X=Pn}  ̄fbnn,c(X)\n",
    "# 12: P'n+1 = Pn − ηgn\n",
    "# 13: return Pn+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: assert(X_n) is numpy array\n",
    "def payment_func(P_n, b_n, Y_n, context):\n",
    "    \"\"\"\n",
    "    P_n: the price vector at previous timestep (t=n)\n",
    "    b_n: the bid at previous timestep (in $ / model_score)\n",
    "    Y_n: the test Y data set\n",
    "    \"\"\"\n",
    "    feature_options = sorted(list((idx, p) for (idx, p) in enumerate(P_n) if p <= b_n), key=operator.itemgetter(1))\n",
    "    gain_func = context.get('gain_func')\n",
    "    if gain_func is None:\n",
    "        return None\n",
    "    \n",
    "    X_n = context.get('X_n')\n",
    "    X_n_train, X_n_test, y_n_train, y_n_test = train_test_split(X_n, Y_n, test_size=0.1, random_state=SEED)\n",
    "    \n",
    "    # Gain results by slice index\n",
    "    feature_indices = []\n",
    "    gain_results = []\n",
    "    for (idx, (feature_idx, feature_price)) in enumerate(feature_options):\n",
    "        _train = get_original_columns(X_n_train, feature_idxs=feature_options[:idx+1])\n",
    "        _test = get_original_columns(X_n_test, feature_idxs=feature_options[:idx+1])\n",
    "        clf.fit(_train, y_n_train)\n",
    "        gain_results[idx] = clf.score(_test, y_n_test) # TODO: change to RMSE?\n",
    "        feature_indices.append(feature_idx)\n",
    "\n",
    "    \n",
    "    # TODO: refactor\n",
    "    positive_amount = b_n * gain_results[-1]\n",
    "    negative_amount = 0\n",
    "    # Add the bid as the rightmost price\n",
    "    feature_indices += [-1]\n",
    "    P_n += [b_n]\n",
    "    for idx, gain in enumerate(gain_results):\n",
    "        price_idx = feature_indices[idx]\n",
    "        price_idx_plus_one = feature_indices[idx+1]\n",
    "        price_difference = P_n[price_idx_plus_one] - P_n[price_idx]\n",
    "        assert(price_difference >= 0)\n",
    "        negative_amount += price_difference * gain\n",
    "    return positive_amount - negative_amount\n",
    "\n",
    "\n",
    "def get_original_columns(X_n, feature_idxs):\n",
    "    \"\"\"\n",
    "    https://docs.scipy.org/doc/numpy-1.10.0/reference/generated/numpy.ix_.html\n",
    "    TODO: figure out how to use np.ix_\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "def algorithm2():\n",
    "    pass\n",
    "\n",
    "\n",
    "context = {\n",
    "    'gain_func': clf,\n",
    "    'X_n': X_n,\n",
    "}\n",
    "payment_func(P_n, b_n, Y_n, context)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
